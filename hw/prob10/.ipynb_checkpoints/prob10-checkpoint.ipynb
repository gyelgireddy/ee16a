{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE16A Homework 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Audio File Matching\n",
    "\n",
    "This notebook continues the audio file matching problem. Be sure to have `song.wav` and `clip.wav` in the same directory as the notebook.\n",
    "\n",
    "In this notebook, we will look at the problem of searching for a small audio clip inside a song.\n",
    "\n",
    "The song \"Mandelbrot Set\" by Jonathan Coulton is licensed under <a href=\"http://creativecommons.org/licenses/by-nc/3.0/\">CC BY-NC 3.0</a>.\n",
    "\n",
    "If you have trouble playing the audio file in IPython, try opening it in a different browser. There were problems with Safari, but Chrome works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"temp.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import operator\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline\n",
    "\n",
    "given_file = 'song.wav'\n",
    "target_file = 'clip.wav'\n",
    "rate_given,  given_signal  = scipy.io.wavfile.read(given_file)\n",
    "rate_target, target_signal = scipy.io.wavfile.read(target_file)\n",
    "given_signal  = given_signal[:2000000].astype(float)\n",
    "target_signal = target_signal.astype(float)\n",
    "def play_clip(start, end, signal=given_signal):\n",
    "    scipy.io.wavfile.write('temp.wav', rate_given, signal[start:end].astype(np.int16))\n",
    "    return Audio(url='temp.wav', autoplay=True)\n",
    "\n",
    "def run_comparison(target_signal, given_signal, idxs=None):\n",
    "    # Run everything if not called with idxs set to something\n",
    "    if idxs is None:\n",
    "        idxs = [i for i in range(len(given_signal)-len(target_signal))]\n",
    "    return idxs, [vector_compare(target_signal, given_signal[i:i+len(target_signal)])\n",
    "                for i in idxs]\n",
    "\n",
    "play_clip(0, len(given_signal))\n",
    "\n",
    "# scipy.io.wavfile.write(target_file, rate_given, (-0.125*given_signal[1380000:1380000+70000]).astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the song onto the variable `given_signal` and load the short clip onto the variable `target_signal`. Your job is to finish the code that will identify the short clip's location in the song. The clip we are trying to find will play after executing the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Audio(url=target_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to define the function `vector_compare` and run the following code. Because the song has a lot of data, you should use the provided examples from the previous parts of the problem before running the later code. Do your results here make sense given your answers to previous parts of the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_compare(desired_vec, test_vec):\n",
    "    \"\"\"This function compares two vectors, returning a number.\n",
    "    The test vector with the highest return value is regarded as being closest to the desired vector.\"\"\"\n",
    "    # Hint: Use transpose for the first argument of np.dot\n",
    "    # YOUR CODE HERE\n",
    "    np.dot(transpose, test_vec)\n",
    "    np.dot(desired_vec, test_vec)\n",
    "\n",
    "print(vector_compare(np.array([1,1,1]), np.array([1,1,1])))\n",
    "print(vector_compare(np.array([1,1,1]), np.array([-1,-1,-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(vector_compare(np.array([1,2,3]), np.array([1,2,3])))\n",
    "print(vector_compare(np.array([1,2,3]), np.array([2,3,4])))\n",
    "print(vector_compare(np.array([1,2,3]), np.array([3,4,5])))\n",
    "print(vector_compare(np.array([1,2,3]), np.array([4,5,6])))\n",
    "print(vector_compare(np.array([1,2,3]), np.array([5,6,7])))\n",
    "print(vector_compare(np.array([1,2,3]), np.array([6,7,8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d)\n",
    "\n",
    "Run the following code that runs `vector_compare` on every subsequence in the song - it will probably take at least 5 minutes. How do you interpret this plot to find where the clip is in the song?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "idxs, song_compare = run_comparison(target_signal, given_signal)\n",
    "t1 = time.time()\n",
    "plt.plot(idxs, song_compare)\n",
    "print (\"That took %(time).2f minutes to run\" % {'time':(t1-t0)/60.0} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (e)\n",
    "\n",
    "In the space below, write code that uses `song_compare` to print the index of `given_signal` where `target_signal` begins. Then, verify that your answer is correct by playing the song at that index using the `play_clip` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
